{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-04T12:12:46.701540Z",
     "start_time": "2025-06-04T12:12:46.699058Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T12:12:46.861011Z",
     "start_time": "2025-06-04T12:12:46.857852Z"
    }
   },
   "cell_type": "code",
   "source": "torch.set_float32_matmul_precision(\"medium\")",
   "id": "5b7e965c2189fb07",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T12:15:01.766259Z",
     "start_time": "2025-06-04T12:15:01.760955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TestNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TestNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ],
   "id": "8995ba2aac6b20ac",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T12:15:11.758572Z",
     "start_time": "2025-06-04T12:15:11.727956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "seed = 13\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "use_accel = True\n",
    "save_model = True\n",
    "dry_run = False\n",
    "log_interval = 50\n",
    "\n",
    "batch_size = 6\n",
    "test_batch_size = 1\n",
    "epochs = 1\n",
    "\n",
    "lr = 0.001\n",
    "gamma = 0.99\n",
    "\n",
    "if use_accel:\n",
    "    device = torch.accelerator.current_accelerator()\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "train_kwargs = {'batch_size': batch_size}\n",
    "test_kwargs = {'batch_size': test_batch_size}\n",
    "\n",
    "if use_accel:\n",
    "    accel_kwargs = {'num_workers': 1,\n",
    "                   'pin_memory': True,\n",
    "                   'shuffle': True}\n",
    "    train_kwargs.update(accel_kwargs)\n",
    "    test_kwargs.update(accel_kwargs)\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "dataset1 = MNIST('../data/datasets/', train=True, download=True,\n",
    "                   transform=transform)\n",
    "dataset2 = MNIST('../data/datasets/', train=False,\n",
    "                   transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset1,**train_kwargs)\n",
    "test_loader = DataLoader(dataset2, **test_kwargs)"
   ],
   "id": "52b06edcd6b08244",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T12:15:12.557343Z",
     "start_time": "2025-06-04T12:15:12.552704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            if dry_run:\n",
    "                break"
   ],
   "id": "70a19e9954d630a6",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T12:15:12.960646Z",
     "start_time": "2025-06-04T12:15:12.957186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ],
   "id": "58ddbbc837935fd9",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T12:16:54.229399Z",
     "start_time": "2025-06-04T12:16:54.219675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "network = TestNet().to(device)\n",
    "optimizer = optim.Adadelta(network.parameters(), lr=lr)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=gamma)"
   ],
   "id": "b0c76339593f9bf3",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T12:17:18.097856Z",
     "start_time": "2025-06-04T12:16:54.809059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train(network, device, train_loader, optimizer, epoch)\n",
    "    test(network, device, test_loader)\n",
    "    scheduler.step()\n",
    "\n",
    "if save_model:\n",
    "    torch.save(network.state_dict(), \"../checkpoints/MNIST/mnist_cnn.pt\")"
   ],
   "id": "7efa47ec43c612f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.325482\n",
      "Train Epoch: 1 [300/60000 (0%)]\tLoss: 2.314932\n",
      "Train Epoch: 1 [600/60000 (1%)]\tLoss: 2.196333\n",
      "Train Epoch: 1 [900/60000 (2%)]\tLoss: 2.243163\n",
      "Train Epoch: 1 [1200/60000 (2%)]\tLoss: 2.233226\n",
      "Train Epoch: 1 [1500/60000 (2%)]\tLoss: 2.219179\n",
      "Train Epoch: 1 [1800/60000 (3%)]\tLoss: 2.199193\n",
      "Train Epoch: 1 [2100/60000 (4%)]\tLoss: 2.286519\n",
      "Train Epoch: 1 [2400/60000 (4%)]\tLoss: 2.173641\n",
      "Train Epoch: 1 [2700/60000 (4%)]\tLoss: 2.243483\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 2.319979\n",
      "Train Epoch: 1 [3300/60000 (6%)]\tLoss: 2.281537\n",
      "Train Epoch: 1 [3600/60000 (6%)]\tLoss: 2.184864\n",
      "Train Epoch: 1 [3900/60000 (6%)]\tLoss: 2.228739\n",
      "Train Epoch: 1 [4200/60000 (7%)]\tLoss: 2.116406\n",
      "Train Epoch: 1 [4500/60000 (8%)]\tLoss: 2.161614\n",
      "Train Epoch: 1 [4800/60000 (8%)]\tLoss: 2.125653\n",
      "Train Epoch: 1 [5100/60000 (8%)]\tLoss: 2.126293\n",
      "Train Epoch: 1 [5400/60000 (9%)]\tLoss: 2.093744\n",
      "Train Epoch: 1 [5700/60000 (10%)]\tLoss: 2.178246\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 2.223331\n",
      "Train Epoch: 1 [6300/60000 (10%)]\tLoss: 2.118225\n",
      "Train Epoch: 1 [6600/60000 (11%)]\tLoss: 1.980437\n",
      "Train Epoch: 1 [6900/60000 (12%)]\tLoss: 2.097069\n",
      "Train Epoch: 1 [7200/60000 (12%)]\tLoss: 2.043519\n",
      "Train Epoch: 1 [7500/60000 (12%)]\tLoss: 2.033383\n",
      "Train Epoch: 1 [7800/60000 (13%)]\tLoss: 2.018998\n",
      "Train Epoch: 1 [8100/60000 (14%)]\tLoss: 1.961128\n",
      "Train Epoch: 1 [8400/60000 (14%)]\tLoss: 2.016155\n",
      "Train Epoch: 1 [8700/60000 (14%)]\tLoss: 1.919078\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 2.040550\n",
      "Train Epoch: 1 [9300/60000 (16%)]\tLoss: 2.002645\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 1.968472\n",
      "Train Epoch: 1 [9900/60000 (16%)]\tLoss: 2.014220\n",
      "Train Epoch: 1 [10200/60000 (17%)]\tLoss: 1.724192\n",
      "Train Epoch: 1 [10500/60000 (18%)]\tLoss: 1.780137\n",
      "Train Epoch: 1 [10800/60000 (18%)]\tLoss: 2.070425\n",
      "Train Epoch: 1 [11100/60000 (18%)]\tLoss: 2.014773\n",
      "Train Epoch: 1 [11400/60000 (19%)]\tLoss: 1.664630\n",
      "Train Epoch: 1 [11700/60000 (20%)]\tLoss: 1.884478\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 1.683641\n",
      "Train Epoch: 1 [12300/60000 (20%)]\tLoss: 1.748936\n",
      "Train Epoch: 1 [12600/60000 (21%)]\tLoss: 1.577466\n",
      "Train Epoch: 1 [12900/60000 (22%)]\tLoss: 1.590210\n",
      "Train Epoch: 1 [13200/60000 (22%)]\tLoss: 1.880594\n",
      "Train Epoch: 1 [13500/60000 (22%)]\tLoss: 1.699197\n",
      "Train Epoch: 1 [13800/60000 (23%)]\tLoss: 1.663499\n",
      "Train Epoch: 1 [14100/60000 (24%)]\tLoss: 1.585383\n",
      "Train Epoch: 1 [14400/60000 (24%)]\tLoss: 1.855974\n",
      "Train Epoch: 1 [14700/60000 (24%)]\tLoss: 1.989409\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 1.642626\n",
      "Train Epoch: 1 [15300/60000 (26%)]\tLoss: 1.652669\n",
      "Train Epoch: 1 [15600/60000 (26%)]\tLoss: 1.870439\n",
      "Train Epoch: 1 [15900/60000 (26%)]\tLoss: 1.557607\n",
      "Train Epoch: 1 [16200/60000 (27%)]\tLoss: 1.735699\n",
      "Train Epoch: 1 [16500/60000 (28%)]\tLoss: 1.112461\n",
      "Train Epoch: 1 [16800/60000 (28%)]\tLoss: 1.536931\n",
      "Train Epoch: 1 [17100/60000 (28%)]\tLoss: 1.310363\n",
      "Train Epoch: 1 [17400/60000 (29%)]\tLoss: 1.858810\n",
      "Train Epoch: 1 [17700/60000 (30%)]\tLoss: 1.627083\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 1.200819\n",
      "Train Epoch: 1 [18300/60000 (30%)]\tLoss: 1.326141\n",
      "Train Epoch: 1 [18600/60000 (31%)]\tLoss: 1.636208\n",
      "Train Epoch: 1 [18900/60000 (32%)]\tLoss: 1.391864\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.306135\n",
      "Train Epoch: 1 [19500/60000 (32%)]\tLoss: 1.542071\n",
      "Train Epoch: 1 [19800/60000 (33%)]\tLoss: 1.302867\n",
      "Train Epoch: 1 [20100/60000 (34%)]\tLoss: 1.529659\n",
      "Train Epoch: 1 [20400/60000 (34%)]\tLoss: 1.532883\n",
      "Train Epoch: 1 [20700/60000 (34%)]\tLoss: 1.268699\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 1.643412\n",
      "Train Epoch: 1 [21300/60000 (36%)]\tLoss: 1.223363\n",
      "Train Epoch: 1 [21600/60000 (36%)]\tLoss: 1.426353\n",
      "Train Epoch: 1 [21900/60000 (36%)]\tLoss: 1.335551\n",
      "Train Epoch: 1 [22200/60000 (37%)]\tLoss: 1.712845\n",
      "Train Epoch: 1 [22500/60000 (38%)]\tLoss: 1.261154\n",
      "Train Epoch: 1 [22800/60000 (38%)]\tLoss: 1.252633\n",
      "Train Epoch: 1 [23100/60000 (38%)]\tLoss: 0.656696\n",
      "Train Epoch: 1 [23400/60000 (39%)]\tLoss: 1.667933\n",
      "Train Epoch: 1 [23700/60000 (40%)]\tLoss: 0.874245\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 1.822017\n",
      "Train Epoch: 1 [24300/60000 (40%)]\tLoss: 1.336086\n",
      "Train Epoch: 1 [24600/60000 (41%)]\tLoss: 0.691480\n",
      "Train Epoch: 1 [24900/60000 (42%)]\tLoss: 1.365235\n",
      "Train Epoch: 1 [25200/60000 (42%)]\tLoss: 1.030189\n",
      "Train Epoch: 1 [25500/60000 (42%)]\tLoss: 1.170318\n",
      "Train Epoch: 1 [25800/60000 (43%)]\tLoss: 0.780222\n",
      "Train Epoch: 1 [26100/60000 (44%)]\tLoss: 0.649676\n",
      "Train Epoch: 1 [26400/60000 (44%)]\tLoss: 1.024414\n",
      "Train Epoch: 1 [26700/60000 (44%)]\tLoss: 0.971038\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 1.218212\n",
      "Train Epoch: 1 [27300/60000 (46%)]\tLoss: 0.931364\n",
      "Train Epoch: 1 [27600/60000 (46%)]\tLoss: 1.120810\n",
      "Train Epoch: 1 [27900/60000 (46%)]\tLoss: 1.334915\n",
      "Train Epoch: 1 [28200/60000 (47%)]\tLoss: 1.309053\n",
      "Train Epoch: 1 [28500/60000 (48%)]\tLoss: 1.111583\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.927849\n",
      "Train Epoch: 1 [29100/60000 (48%)]\tLoss: 1.498610\n",
      "Train Epoch: 1 [29400/60000 (49%)]\tLoss: 1.195588\n",
      "Train Epoch: 1 [29700/60000 (50%)]\tLoss: 1.029546\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 1.069280\n",
      "Train Epoch: 1 [30300/60000 (50%)]\tLoss: 0.842405\n",
      "Train Epoch: 1 [30600/60000 (51%)]\tLoss: 0.771971\n",
      "Train Epoch: 1 [30900/60000 (52%)]\tLoss: 1.285187\n",
      "Train Epoch: 1 [31200/60000 (52%)]\tLoss: 1.214192\n",
      "Train Epoch: 1 [31500/60000 (52%)]\tLoss: 0.767534\n",
      "Train Epoch: 1 [31800/60000 (53%)]\tLoss: 0.687171\n",
      "Train Epoch: 1 [32100/60000 (54%)]\tLoss: 1.909709\n",
      "Train Epoch: 1 [32400/60000 (54%)]\tLoss: 0.661017\n",
      "Train Epoch: 1 [32700/60000 (54%)]\tLoss: 0.517891\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 0.726370\n",
      "Train Epoch: 1 [33300/60000 (56%)]\tLoss: 1.731457\n",
      "Train Epoch: 1 [33600/60000 (56%)]\tLoss: 1.190466\n",
      "Train Epoch: 1 [33900/60000 (56%)]\tLoss: 0.933928\n",
      "Train Epoch: 1 [34200/60000 (57%)]\tLoss: 1.118793\n",
      "Train Epoch: 1 [34500/60000 (58%)]\tLoss: 1.806670\n",
      "Train Epoch: 1 [34800/60000 (58%)]\tLoss: 0.483409\n",
      "Train Epoch: 1 [35100/60000 (58%)]\tLoss: 0.610798\n",
      "Train Epoch: 1 [35400/60000 (59%)]\tLoss: 1.257058\n",
      "Train Epoch: 1 [35700/60000 (60%)]\tLoss: 1.297622\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.754497\n",
      "Train Epoch: 1 [36300/60000 (60%)]\tLoss: 0.978963\n",
      "Train Epoch: 1 [36600/60000 (61%)]\tLoss: 0.856678\n",
      "Train Epoch: 1 [36900/60000 (62%)]\tLoss: 0.536544\n",
      "Train Epoch: 1 [37200/60000 (62%)]\tLoss: 0.724247\n",
      "Train Epoch: 1 [37500/60000 (62%)]\tLoss: 0.983972\n",
      "Train Epoch: 1 [37800/60000 (63%)]\tLoss: 0.939841\n",
      "Train Epoch: 1 [38100/60000 (64%)]\tLoss: 0.423405\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.680082\n",
      "Train Epoch: 1 [38700/60000 (64%)]\tLoss: 1.294174\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 1.019480\n",
      "Train Epoch: 1 [39300/60000 (66%)]\tLoss: 0.668845\n",
      "Train Epoch: 1 [39600/60000 (66%)]\tLoss: 1.018281\n",
      "Train Epoch: 1 [39900/60000 (66%)]\tLoss: 0.489532\n",
      "Train Epoch: 1 [40200/60000 (67%)]\tLoss: 0.753134\n",
      "Train Epoch: 1 [40500/60000 (68%)]\tLoss: 0.377898\n",
      "Train Epoch: 1 [40800/60000 (68%)]\tLoss: 1.102386\n",
      "Train Epoch: 1 [41100/60000 (68%)]\tLoss: 0.966814\n",
      "Train Epoch: 1 [41400/60000 (69%)]\tLoss: 1.096746\n",
      "Train Epoch: 1 [41700/60000 (70%)]\tLoss: 0.658660\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.806863\n",
      "Train Epoch: 1 [42300/60000 (70%)]\tLoss: 1.002214\n",
      "Train Epoch: 1 [42600/60000 (71%)]\tLoss: 0.621702\n",
      "Train Epoch: 1 [42900/60000 (72%)]\tLoss: 0.849436\n",
      "Train Epoch: 1 [43200/60000 (72%)]\tLoss: 0.502202\n",
      "Train Epoch: 1 [43500/60000 (72%)]\tLoss: 0.939424\n",
      "Train Epoch: 1 [43800/60000 (73%)]\tLoss: 0.425298\n",
      "Train Epoch: 1 [44100/60000 (74%)]\tLoss: 1.080941\n",
      "Train Epoch: 1 [44400/60000 (74%)]\tLoss: 1.104914\n",
      "Train Epoch: 1 [44700/60000 (74%)]\tLoss: 0.726568\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.747112\n",
      "Train Epoch: 1 [45300/60000 (76%)]\tLoss: 0.648002\n",
      "Train Epoch: 1 [45600/60000 (76%)]\tLoss: 0.556594\n",
      "Train Epoch: 1 [45900/60000 (76%)]\tLoss: 0.601238\n",
      "Train Epoch: 1 [46200/60000 (77%)]\tLoss: 0.690626\n",
      "Train Epoch: 1 [46500/60000 (78%)]\tLoss: 0.457167\n",
      "Train Epoch: 1 [46800/60000 (78%)]\tLoss: 0.386162\n",
      "Train Epoch: 1 [47100/60000 (78%)]\tLoss: 0.773862\n",
      "Train Epoch: 1 [47400/60000 (79%)]\tLoss: 1.170507\n",
      "Train Epoch: 1 [47700/60000 (80%)]\tLoss: 1.575957\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.307830\n",
      "Train Epoch: 1 [48300/60000 (80%)]\tLoss: 0.413010\n",
      "Train Epoch: 1 [48600/60000 (81%)]\tLoss: 1.093184\n",
      "Train Epoch: 1 [48900/60000 (82%)]\tLoss: 1.303803\n",
      "Train Epoch: 1 [49200/60000 (82%)]\tLoss: 0.975400\n",
      "Train Epoch: 1 [49500/60000 (82%)]\tLoss: 0.519862\n",
      "Train Epoch: 1 [49800/60000 (83%)]\tLoss: 0.458201\n",
      "Train Epoch: 1 [50100/60000 (84%)]\tLoss: 0.585724\n",
      "Train Epoch: 1 [50400/60000 (84%)]\tLoss: 0.630250\n",
      "Train Epoch: 1 [50700/60000 (84%)]\tLoss: 0.691414\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 0.683521\n",
      "Train Epoch: 1 [51300/60000 (86%)]\tLoss: 0.842817\n",
      "Train Epoch: 1 [51600/60000 (86%)]\tLoss: 0.140627\n",
      "Train Epoch: 1 [51900/60000 (86%)]\tLoss: 0.999198\n",
      "Train Epoch: 1 [52200/60000 (87%)]\tLoss: 0.768373\n",
      "Train Epoch: 1 [52500/60000 (88%)]\tLoss: 1.136553\n",
      "Train Epoch: 1 [52800/60000 (88%)]\tLoss: 0.321383\n",
      "Train Epoch: 1 [53100/60000 (88%)]\tLoss: 0.273615\n",
      "Train Epoch: 1 [53400/60000 (89%)]\tLoss: 0.360233\n",
      "Train Epoch: 1 [53700/60000 (90%)]\tLoss: 0.513806\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.649106\n",
      "Train Epoch: 1 [54300/60000 (90%)]\tLoss: 0.279328\n",
      "Train Epoch: 1 [54600/60000 (91%)]\tLoss: 0.772280\n",
      "Train Epoch: 1 [54900/60000 (92%)]\tLoss: 0.831932\n",
      "Train Epoch: 1 [55200/60000 (92%)]\tLoss: 0.295729\n",
      "Train Epoch: 1 [55500/60000 (92%)]\tLoss: 0.415184\n",
      "Train Epoch: 1 [55800/60000 (93%)]\tLoss: 0.456417\n",
      "Train Epoch: 1 [56100/60000 (94%)]\tLoss: 0.791719\n",
      "Train Epoch: 1 [56400/60000 (94%)]\tLoss: 0.399744\n",
      "Train Epoch: 1 [56700/60000 (94%)]\tLoss: 0.317158\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 0.678530\n",
      "Train Epoch: 1 [57300/60000 (96%)]\tLoss: 0.459592\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.396975\n",
      "Train Epoch: 1 [57900/60000 (96%)]\tLoss: 0.831091\n",
      "Train Epoch: 1 [58200/60000 (97%)]\tLoss: 0.553885\n",
      "Train Epoch: 1 [58500/60000 (98%)]\tLoss: 0.679754\n",
      "Train Epoch: 1 [58800/60000 (98%)]\tLoss: 0.694497\n",
      "Train Epoch: 1 [59100/60000 (98%)]\tLoss: 0.285044\n",
      "Train Epoch: 1 [59400/60000 (99%)]\tLoss: 0.364487\n",
      "Train Epoch: 1 [59700/60000 (100%)]\tLoss: 1.118492\n",
      "\n",
      "Test set: Average loss: 0.4938, Accuracy: 8670/10000 (87%)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "749296a0fbb735de"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
